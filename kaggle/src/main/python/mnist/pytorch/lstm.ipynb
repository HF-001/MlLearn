{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demo.ipynb', '.ipynb_checkpoints', 'train.csv', 'graph.png', 'lstm.ipynb', 'sample_submission.csv', 'test.csv', 'rnn.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAJX0lEQVR4nO3de6zXdR3H8dfnd25yRC6BqBC3M5kiDQJWiKsJYyRmjNliq6nRZWNBMWNZoWVkMVfqrOSiEoJjlptUw2bOYnlGNyoTIiMimMpg46pwgkQ4l29/AA7t933/4vzO5fXjPB8bG4f37/M7X3HP89n47Pv9pSzLBMBPobsvAEBxxAmYIk7AFHECpogTMEWcgCniBEwRZ4VJKY1IKT2bUjqSUtqfUlqWUqrOee3CM69pSimtTinVdfX1ov2Is/KskHRQ0hWS3ivpeknz3/milNINkhZJmiZphKQGSfd02VWibMRZeUZKeirLsjezLNsv6TlJY4q8bo6kx7Is25Zl2RFJ35b0qa67TJSLOCvPDyR9PKVUn1IaIulGnQ70ncZI2nrO11slXZZSGtAF14gOQJyVZ6NOh/dvSXsl/UXS+iKv6y2p6Zyvz/7+kk69OnQY4qwgKaWCpF9K+pmkiyUNlNRf0neLvPy4pD7nfH3298c68xrRcYizsrxL0lBJy7IsO5ll2WuS1kj6cJHXbpM07pyvx0k6cGYNKgBxVpAsyw5LekXSvJRSdUqpn07/w8/WIi9fK+mzKaVrUkr9JX1d0uNddrEoG3FWno9KmiHpkKRdklokLUwpDUspHU8pDZOkLMuek3SfpEZJu8/8Wtw9l4z2SNxsDXhi5wRMESdgijgBU8QJmCp6N8NZ0wuz+dcioJNtaFuXiv05OydgijgBU8QJmCJOwBRxAqaIEzBFnIAp4gRMESdgijgBU8QJmCJOwBRxAqaIEzBFnIAp4gRMESdgijgBU8QJmCJOwBRxAqaIEzBFnIAp4gRMESdgijgBU8QJmCJOwBRxAqaIEzBFnIAp4gRMESdgijgBU8QJmCJOwBRxAqaIEzBFnIAp4gRMESdgijgBU8QJmCJOwBRxAqaIEzBV3d0XgLcr1NfH88suLev999w8JJy/+KWlZb1/OWpSVe5sxj9vCte23jMonBc2bmnXNXUndk7AFHECpogTMEWcgCniBEwRJ2CKo5RuUDV6VO6sfuWRcO2PGn5S1vculPh53Ka2st6/HM1Z/uzpq9aHaxsf6x3OH7ppZjhv3bErnHcHdk7AFHECpogTMEWcgCniBEwRJ2CKOAFTnHN2gjRxTDjf9eX8W6NeavhxR19Ol2k8EZ81fmPJZ8L5HXfl/7fPuvhwuHZqr+Ph/PPzBobzK7/IOSeA/xNxAqaIEzBFnIAp4gRMESdgijgBU5xztsPhuZPD+fJFy8L5+Lruu2eyMzUeGx3OB67/Rzhf/ckP5M5mlbifs5SqE6ms9d2BnRMwRZyAKeIETBEnYIo4AVPECZgiTsAU55xFZJPHhfMnv/ZAOB9ZfVE4vzBPOaUFA34XzqfcfUc4v7nfnzryct6mdeibnfbenYWdEzBFnIAp4gRMESdgijgBU8QJmCJOwFSPPOcs1NeH8xtWbQznpc4xa1L+c2ml+HMoy/Xnk/F9i3uaB4TzNXOCz7H849/CtXvvvC6cb//C0nAe/b01Z/E+suTw2HB+9Z2HwnlLOO0e7JyAKeIETBEnYIo4AVPECZgiTsBUzzxKuXxQOB9a8/dw3lbipq9SRyWl1kdWNTWE82enxR8/2LJvf4nvkH9cUhh7dbhywW1Ph/Ny/t5+/p/+4drffDU+xqnd80I4d8TOCZgiTsAUcQKmiBMwRZyAKeIETBEnYKpHnnO2vPxqOP/mylvD+Qdvvz+c9y/Et5SVY+13PhLO++3bFM5L3S7XNDP/1qspi/4Qrv1031fDeSlTX5qdO+s7Pz4jrX258s4xS2HnBEwRJ2CKOAFTxAmYIk7AFHECpogTMJWyLP8muumF2Z34EMcKdm38GMZnfromnJdzP+f2U/HaWx9dGM6z9zWF883XPn6+l/SWJ48NCef3PfGxcD50SXyOeqHa0Lau6PNM2TkBU8QJmCJOwBRxAqaIEzBFnIAp4gRMcc7ZCXaunRDOt097tIuu5H8VSvw83nQy/2P45q2aH64dvnJHOG89/Fo476k45wQqDHECpogTMEWcgCniBEwRJ2CKOAFTPfK5tZ1t9OL4PK8wrft+Jtak/HNMSfrc5vxn9g7//l/Dta1vvNGua0Jx7JyAKeIETBEnYIo4AVPECZgiTsAURyntkE0eF853zow/Zi96NObullPh2voU38V3aVVdOG8ucRPgIxOeyJ3de9Ut8eIt2+I5zgs7J2CKOAFTxAmYIk7AFHECpogTMEWcgKkeec5ZPWRwON+7vG843zBxRTjvX7gonN/yyozc2et3Dw/XHpgYv/evb78/nJe6tkl1zbmzY6MuCdf23hKOcZ7YOQFTxAmYIk7AFHECpogTMEWcgCniBEz1yHPOgx+KzxJXjF0ezvsWasP54oPj4+9/b0PurK7xhXDt4MZwrEkNC8P5v2Y9HL9B4OCEop9U95beT7X7rVEEOydgijgBU8QJmCJOwBRxAqaIEzBFnICpC/acM3q27C++9UC4ttQ55l37J4Xz7dPi+x7rjsZnmeWofT3+iL9yDNpc4qG36FDsnIAp4gRMESdgijgBU8QJmCJOwNQFe5Sy7yv5j3gs9XjIuXumhPMDM+Kfaa1Hm8J5ZxoxeU84r0nxUUupjwhE12HnBEwRJ2CKOAFTxAmYIk7AFHECpogTMFWx55ypri6cX97nWO6sTW3h2t83viecjzy6KZyXurbW918TziO7bov/l/121PfCeXPWK5yX+rtB12HnBEwRJ2CKOAFTxAmYIk7AFHECpogTMFW555xV8X2JfWtPtPu9H5q9Opw/ct2UcN6nxPf+4bCV53tJ5yE+Yy1ld8up3FmvQ/kzdDx2TsAUcQKmiBMwRZyAKeIETBEnYIo4AVOVe85ZWxPOX9w5InfWeEXvcO3UXsfj+ZXPhPNCiZ953XnH5MQHF4Tzwc/nP3O3asvmjr4cBNg5AVPECZgiTsAUcQKmiBMwRZyAKeIETKUsy/9AxumF2RfkpzW2XT8+nO/6RHyG+vyND4bzd1fHz4bddDL/XtQ5v5obri1l9NL4s0Fbt+0o6/3R8Ta0rUvF/pydEzBFnIAp4gRMESdgijgBU8QJmOqRRymAE45SgApDnIAp4gRMESdgijgBU8QJmCJOwBRxAqaIEzBFnIAp4gRMESdgijgBU8QJmCJOwFR4PyeA7sPOCZgiTsAUcQKmiBMwRZyAKeIETP0XZaeD5/iGq5AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(r\"./train.csv\",dtype = np.float32)\n",
    "\n",
    "# split data into features(pixels) and labels(numbers from 0 to 9)\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
    "\n",
    "# train test split. Size of train data is 80% and size of test data is 20%. \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) \n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "plt.imshow(features_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('graph.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "\n",
    "        # One time step\n",
    "        out, (hn, cn) = self.rnn(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 8000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel(\n",
      "  (rnn): LSTM(28, 100, batch_first=True)\n",
      "  (fc): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# Create RNN\n",
    "input_dim = 28    # input dimension\n",
    "hidden_dim = 100  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "print(model)\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 2.292961359024048  Accuracy: 14 %\n",
      "Iteration: 1000  Loss: 2.28273868560791  Accuracy: 18 %\n",
      "Iteration: 1500  Loss: 1.9387753009796143  Accuracy: 37 %\n",
      "Iteration: 2000  Loss: 1.0113554000854492  Accuracy: 68 %\n",
      "Iteration: 2500  Loss: 0.41908779740333557  Accuracy: 86 %\n",
      "Iteration: 3000  Loss: 0.2782303988933563  Accuracy: 90 %\n",
      "Iteration: 3500  Loss: 0.35264790058135986  Accuracy: 92 %\n",
      "Iteration: 4000  Loss: 0.046064771711826324  Accuracy: 94 %\n",
      "Iteration: 4500  Loss: 0.15314814448356628  Accuracy: 94 %\n",
      "Iteration: 5000  Loss: 0.0760568156838417  Accuracy: 94 %\n",
      "Iteration: 5500  Loss: 0.15359018743038177  Accuracy: 95 %\n",
      "Iteration: 6000  Loss: 0.21476222574710846  Accuracy: 95 %\n",
      "Iteration: 6500  Loss: 0.06170235574245453  Accuracy: 95 %\n",
      "Iteration: 7000  Loss: 0.0866951197385788  Accuracy: 96 %\n",
      "Iteration: 7500  Loss: 0.0944705680012703  Accuracy: 96 %\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train  = images.view(-1, seq_dim, input_dim)\n",
    "        labels = labels    \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "         # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 250 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.item())\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.item(), accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
